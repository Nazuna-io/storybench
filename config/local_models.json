{
  "generation_model": {
    "repo_id": "TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF",
    "filename": "tinyllama-1.1b-chat-v0.3.Q2_K.gguf",
    "subdirectory": ""
  },
  "evaluation_model": {
    "repo_id": "TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF",
    "filename": "tinyllama-1.1b-chat-v0.3.Q2_K.gguf",
    "subdirectory": ""
  },
  "use_local_evaluator": true,
  "settings": {
    "temperature": 0.8,
    "max_tokens": 2048,
    "num_runs": 3,
    "vram_limit_percent": 80,
    "auto_evaluate": true
  }
}