version: 1
global_settings:
  temperature: 0.9
  max_tokens: 4096
  num_runs: 3
  vram_limit_percent: 80

models:
  # API Models
  - name: "GPT-4"
    type: "api"
    provider: "openai"
    model_name: "gpt-4"
    
  - name: "Claude-3-Sonnet"
    type: "api"
    provider: "anthropic"
    model_name: "claude-3-sonnet-20240229"
    
  - name: "Gemini-Pro"
    type: "api"
    provider: "gemini"
    model_name: "gemini-pro"
    
  # Local GGUF Models (commented out for initial API focus)
  # - name: "Llama-7B-Chat"
  #   type: "local"
  #   repo_id: "TheBloke/Llama-2-7B-Chat-GGUF"
  #   filename: "llama-2-7b-chat.Q8_0.gguf"
    
  # - name: "CodeLlama-Instruct"
  #   type: "local"
  #   repo_id: "TheBloke/CodeLlama-7B-Instruct-GGUF"
  #   subdirectory: "8bit"

evaluation:
  auto_evaluate: true
  evaluator_models: ["claude-3-sonnet", "gemini-pro"]
  max_retries: 5
