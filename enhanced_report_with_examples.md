# Storybench Model Performance Report

**Generated:** May 29, 2025 at 03:55
**Models Analyzed:** 12
**Total Responses:** 541
**Total Evaluations:** 540

---\n\n## üèÜ Overall Rankings\n\n| Rank | Model | Score | Provider | Responses |\n|------|-------|-------|----------|-----------|\n| ü•á 1 | claude-3-7-sonnet-20250219 | **4.55** | Anthropic | 21/45 |\n| ü•à 2 | claude-opus-4-20250514 | **4.49** | Anthropic | 39/46 |\n| ü•â 3 | gemini-2.5-pro-preview-05-06 | **4.49** | Google | 27/45 |\n|  4 | Qwen/Qwen3-235B-A22B | **4.37** | Deepinfra | 21/45 |\n|  5 | deepseek-ai/DeepSeek-R1 | **4.27** | Deepinfra | 27/45 |\n|  6 | o4-mini | **4.27** | OpenAI | 33/45 |\n|  7 | claude-sonnet-4-20250514 | **4.25** | Anthropic | 33/45 |\n|  8 | gemini-2.5-flash-preview-05-20 | **4.24** | Google | 30/45 |\n|  9 | deepseek-ai/DeepSeek-V3-0324 | **4.24** | Deepinfra | 30/45 |\n|  10 | gpt-4.1 | **4.21** | OpenAI | 24/45 |\n|  11 | gpt-4o | **4.09** | OpenAI | 33/45 |\n|  12 | meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8 | **3.80** | Deepinfra | 24/45 |\n\n## üìä Detailed Scores\n\n| Model | Overall | Creativity | Coherence | Character Depth | Dialogue Quality | Visual Imagination | Conceptual Depth | Adaptability |\n|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n| claude-3-7-sonnet-20250219 | **4.55** | 4.43 | 4.86 | 4.00 | 4.00 | 3.50 | 4.50 | 5.00 |\n| claude-opus-4-20250514 | **4.49** | 4.77 | 4.92 | 3.77 | 3.92 | 4.38 | 4.69 | 5.00 |\n| gemini-2.5-pro-preview-05-06 | **4.49** | 4.78 | 4.89 | 3.78 | 4.00 | 4.44 | 4.56 | 5.00 |\n| Qwen/Qwen3-235B-A22B | **4.37** | 4.29 | 4.86 | 3.43 | 4.00 | 4.57 | 4.43 | 5.00 |\n| deepseek-ai/DeepSeek-R1 | **4.27** | 4.44 | 4.88 | 3.56 | 3.22 | 4.44 | 4.44 | 5.00 |\n| o4-mini | **4.27** | 4.36 | 4.91 | 3.55 | 3.09 | 4.55 | 4.45 | 5.00 |\n| claude-sonnet-4-20250514 | **4.25** | 4.45 | 4.67 | 3.45 | 3.36 | 4.18 | 4.73 | 5.00 |\n| gemini-2.5-flash-preview-05-20 | **4.24** | 4.40 | 5.00 | 3.20 | 3.60 | 4.20 | 4.30 | 5.00 |\n| deepseek-ai/DeepSeek-V3-0324 | **4.24** | 4.30 | 4.80 | 3.40 | 3.20 | 4.40 | 4.60 | 5.00 |\n| gpt-4.1 | **4.21** | 4.38 | 4.75 | 3.50 | 3.75 | 4.25 | 4.38 | 4.50 |\n| gpt-4o | **4.09** | 4.30 | 4.20 | 3.20 | 3.50 | 4.20 | 4.20 | 5.00 |\n| meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8 | **3.80** | 3.88 | 4.12 | 3.00 | 2.88 | 3.88 | 3.88 | 5.00 |