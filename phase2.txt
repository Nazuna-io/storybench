Phase 2: LangChain Integration - Core Context Enhancement (Months 2-4)

Goal: Enhance the Core Engine's context management capabilities using LangChain to prepare for handling much larger contexts and long-form content.

Specific Actions:

Introduce LangChain Dependency:

Add langchain (and relevant sub-packages like langchain-community, langchain-openai, etc.) to your Python project dependencies.
Refactor Context Management (src/storybench/context_manager.py ):

Text Splitters: Integrate LangChain's text splitters (e.g., RecursiveCharacterTextSplitter, TokenTextSplitter) as an alternative or enhancement to your existing truncation logic. This will be crucial for pre-processing very long texts that might serve as context for prompts.
Document Loaders (for future RAG): Familiarize yourself with LangChain's document loaders. While full RAG might be later, understanding how to load and prepare large documents (e.g., screenplays, book chapters if they were to be stored or referenced) is key.
LLM Wrappers: Begin wrapping your existing LLM API calls (OpenAI, Anthropic, Google ) and local model interactions (GGUF ) using LangChain's LLM wrappers. This provides a consistent interface and access to LangChain features.


Memory Modules (Basic): Explore LangChain's basic memory modules (e.g., ConversationBufferMemory) to see how they can help manage context across multi-prompt sequences  if the combined input/output grows very large.

Develop Basic Long-Context Prompting Strategy:

Scenario: Define a test case where a prompt requires a significantly larger piece of context than your current system comfortably handles (but still within a single LLM call for now, using LangChain's text splitters for input preparation if needed).
Implementation:
Modify the Evaluation Engine to use the LangChain-enhanced Context Manager to prepare this long context.
Ensure the LLM interaction (via LangChain wrappers) can handle this.
Goal: Validate that LangChain helps manage input that would previously have been difficult or heavily truncated.

Testing:

Update existing tests for context management.
Add new tests specifically for LangChain-based text splitting and LLM interactions.
Test with at least one LLM that has a very large context window to understand its behavior with LangChain-prepared inputs.
